<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academia 4.3.1">
  <meta name="generator" content="Hugo 0.68.3" />

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Nathan Cornille">

  
  
  
    
  
  <meta name="description" content="This blog post will give a less technical explanation of the main ideas from my (first!) paper Critical Analysis of Deconfounded Pretraining to Improve Visio-Linguistic Models. Let&rsquo;s dive right into it.
The goal: out-of-distribution performance Machine learning has improved a lot in its ability to learn an accurate predictive model of various kinds of data. Specifically for data that is visual (in the form of pixels) or linguistic (in the form of natural language) great strides have been made.">

  
  <link rel="alternate" hreflang="en-us" href="https://nathancornille.github.io/posts/p1/">

  


  

  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Open+Sans|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academia.min.bcef5eaccde0f18047d8dcec72cc428c.css">

  

  
  
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://nathancornille.github.io/posts/p1/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Nathan Cornille">
  <meta property="og:url" content="https://nathancornille.github.io/posts/p1/">
  <meta property="og:title" content="Taking automatic deconfounding for out-of-distribution performance under the loop | Nathan Cornille">
  <meta property="og:description" content="This blog post will give a less technical explanation of the main ideas from my (first!) paper Critical Analysis of Deconfounded Pretraining to Improve Visio-Linguistic Models. Let&rsquo;s dive right into it.
The goal: out-of-distribution performance Machine learning has improved a lot in its ability to learn an accurate predictive model of various kinds of data. Specifically for data that is visual (in the form of pixels) or linguistic (in the form of natural language) great strides have been made."><meta property="og:image" content="https://nathancornille.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://nathancornille.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2022-03-17T00:00:00&#43;01:00">
  
  <meta property="article:modified_time" content="2022-03-17T00:00:00&#43;01:00">
  

  


  





  <title>Taking automatic deconfounding for out-of-distribution performance under the loop | Nathan Cornille</title>

</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Nathan Cornille</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation"><span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">
      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#cv"><span>CV</span></a>
        </li>

        
        

      

        

        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>
    </div>
  </div>
</nav>


  <article class="article py-5" itemscope itemtype="http://schema.org/Article">

  












    

    
    
    
    <div class="article-container py-3">
      <h1 itemprop="name">Taking automatic deconfounding for out-of-distribution performance under the loop</h1>

      

      
      



<meta content="2022-03-17 00:00:00 &#43;0100 CET" itemprop="datePublished">
<meta content="2022-03-17 00:00:00 &#43;0100 CET" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Mar 17, 2022</time>
  </span>
  

  

  

  
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://nathancornille.github.io/posts/p1/&amp;text=Taking%20automatic%20deconfounding%20for%20out-of-distribution%20performance%20under%20the%20loop" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://nathancornille.github.io/posts/p1/&amp;t=Taking%20automatic%20deconfounding%20for%20out-of-distribution%20performance%20under%20the%20loop" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Taking%20automatic%20deconfounding%20for%20out-of-distribution%20performance%20under%20the%20loop&amp;body=https://nathancornille.github.io/posts/p1/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://nathancornille.github.io/posts/p1/&amp;title=Taking%20automatic%20deconfounding%20for%20out-of-distribution%20performance%20under%20the%20loop" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Taking%20automatic%20deconfounding%20for%20out-of-distribution%20performance%20under%20the%20loop%20https://nathancornille.github.io/posts/p1/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://nathancornille.github.io/posts/p1/&amp;title=Taking%20automatic%20deconfounding%20for%20out-of-distribution%20performance%20under%20the%20loop" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

      














      
      
    </div>
  </div>
</div>

  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      <p>This blog post will give a less technical explanation of the main ideas from my (first!) paper <a href="https://www.frontiersin.org/articles/10.3389/frai.2022.736791/full">Critical Analysis of Deconfounded Pretraining to Improve Visio-Linguistic Models</a>.
Let&rsquo;s dive right into it.</p>
<h3 id="the-goal-out-of-distribution-performance">The goal: out-of-distribution performance</h3>
<p>Machine learning has improved a lot in its ability to learn an accurate predictive model of various kinds of data.
Specifically for data that is visual (in the form of pixels) or linguistic (in the form of natural language) great strides have been made.
A big challenge that remains however, is to predict well when the distribution of data on which we train differs from the one on which we want to make predictions: this is called out-of-distribution (or OOD) prediction.
One proposed way of addressing this challenge, is by using <strong>causal</strong> models.</p>
<h3 id="causality-and-ood">Causality and OOD</h3>
<p>You can find a more detailed explanation as well as an example of the link between causal models and OOD prediction in <a href="https://www.frontiersin.org/articles/10.3389/frai.2022.736791/full#h4">section 3 of the paper</a>.
In a nutshell though, in a causal model you chop up (or &lsquo;factorize&rsquo;) the relations in your data into pieces that follow lines of the underlying causality.
For example, when modelling the presence of rain and umbrellas in the street, you&rsquo;ll model 1) the probability of rain (P<sub>R</sub>), 2) the probability of umbrellas <em>given</em> rain (P<sub>U|R</sub>).
The alternative would be to model 1) the probability of umbrellas (P<sub>U</sub>) 2) the probability of rain given umbrellas (P<sub>R|U</sub>).
The link with OOD prediction then comes from the Sparse Mechanism Shift (SMS) assumption proposed by Bernard Schölkopf and others: this assumption states that differences in distribution typically correspond to the change in only a few causal mechanisms.
For example, when we change our distribution by looking at data from a more rainy country, if you factorized the relations causally, only P<sub>R</sub> will change.
If you factorized them the other way however, both factors P<sub>U</sub> and P<sub>R|U</sub> will change.</p>
<h3 id="deconfounding">Deconfounding</h3>
<p>Now, several papers have tried to use this reasoning to create models that are better at OOD prediction.
A particular class of papers that I take under the loop here, are papers that try to automatically do deconfounding in order to learn more causal models.
Deconfounding is a technique to adjust for the effect of a common cause when investigating the relation between two variables.
For example, the prevalence of storks, and the prevalence of new babies is correlated in European countries.
This can mean three things: storks cause babies (by carrying them in), babies cause storks (maybe they attract them in some way), <strong>or</strong> a common cause has an influence on both (say, the socio-economic status of a country, which has an influence both on how much nature there is, as on the birthrates).
If we look at the relation between babies and storks <em>for countries with the same socio-economic status)</em>, we might well find the relation disappears.</p>
<h3 id="issues-with-automatic-deconfounding">Issues with automatic deconfounding</h3>
<p>The tricky thing about doing deconfounding, is that you need to know what is a correct confounder (in our example: socio-economic status) in the first place.</p>
<p>Researchers that have made use of the technique that I take under the loop (which I call <em>AutoDeconfounding</em> or AD), assume it can automatically discover correct confounders just from looking at data.
However, this hasn&rsquo;t been tested explicitly, so we create a dataset to test whether true confounders are actually found.</p>
<p>Moreover, the link between AD and theoretically correct deconfounding hadn&rsquo;t been made explicit yet, so we formalize the assumptions that need to hold for the implementation of AD to match correct deconfounding.</p>
<p>Finally, what <em>has</em> been shown, is that AD improves OOD prediction performance. However, we provide evidence that the improved performance observed in previous experiments isn&rsquo;t actually due to AD.</p>
<h3 id="our-results">Our results</h3>
<h4 id="are-confounders-found">Are confounders found?</h4>
<p>To answer this question, we need ground-truth data of what variables are confounders.
As a confounder is by definition a cause of two other variables, we need to know which variables cause which.
In our case, the variables aren&rsquo;t storks and babies, but the presence of objects in a scene.
The ideal way to test whether a causal relation, is by doing an experiment (e.g., a randomized controlled trial): put an object in a scene (say a raincloud), and observe whether some other object (an umbrella) subsequently appears or not.
As we deemed it too hard to do this kind of live experimentation (it is tricky to drag rainclouds in front of a camera), we went for an approximation instead: human judgement.
We asked crowdworkers to judge the relation between the presence of objects, and took that as our ground truth.</p>
<p>We found that the confounder-finding mechanism <em>did</em> in fact outperform a random baseline in correctly distinguishing causes from non-causal correlates.
However, we found that doing better at confounder-finding did not correlate with a better OOD performance.</p>
<h4 id="is-ad-equivalent-with-deconfounding">Is AD equivalent with deconfounding?</h4>
<p>The actual implementation of AD is somewhat far removed from the theoretical principle.
We made the link more clear by making the assumptions explicit under which the implementation matches the theory.
The assumptions come down to a need for the encoding of the confounder variables to be powerful enough to represent their full state, and the need for the confounders to be mutually independent.</p>
<h4 id="does-ad-improve-ood-performance">Does AD improve OOD performance?</h4>
<p>For our final result, we redo the original experiments that investigate the effect of AD.
We compare a model using AD with a baseline model that doesn&rsquo;t use it. In contrast to previous work, we don&rsquo;t just copy the results from the baseline models as they were originally reported, but reproduce both the AD model as the baseline model ourselves, to get a like-for-like comparison.
In this like-for-like comparison, <em>we no longer observe the improvement in performance</em>.
Moreover, we create a few ablated models, which change AD such as to be less related to theoretical deconfounding, and find that these too don&rsquo;t perform worse than the original AD model.</p>
<h3 id="so-what">So what?</h3>
<p>Our investigation has mainly been a critical story: what things are <em>not</em> yet as they should be.
I think this is how science progresses however: sometimes you advance the field by proposing something new, sometimes you do it by correcting an existing theory.
Hence, I hope this will enable other researchers who are interested in leveraging causality for OOD performance to know which techniques to use, and which techniques still have their limitations.</p>

    </div>

    



    
      








  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="https://nathancornille.github.io/">Nathan Cornille</a></h5>
      
      <p class="card-text" itemprop="description">PhD student, machine learning.</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/#contact" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://twitter.com/Natithan5005" target="_blank" rel="noopener">
              <i class="fab fa-twitter"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://scholar.google.com/citations?user=ke6yJRIAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/Natithan" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://www.linkedin.com/in/nathan-cornille-8240b5110/" target="_blank" rel="noopener">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
    

    

    


  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academia.min.ed6065c7650f4a49a4cb4cb7dd61f885.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  <div class="container">
    <div class="row">
      <div class="col-md-6">
        





      </div>
      <div class="col-md-6">
        <ul class="list-inline network-icon text-right">
          
          
        </ul>
      </div>
    </div>
  </div>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
